{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2019-07-09 16:43:41\n",
    " \n",
    "# Overview\n",
    "*By Ella Wan*\n",
    "\n",
    "Udacity's free A/B Testing course (https://classroom.udacity.com/courses/ud257)\n",
    "is presented by Google and focuses on design and analysis of A/B tests, especailly for online experiments used to test the effectiveness to a website or mobile app. \n",
    "\n",
    "This course covers the content: \n",
    "\n",
    "1) Overview of A/B Testing <br>\n",
    "2) Policy and Ethic for Experiment <br>\n",
    "3) Choosing and Characterizing Metric <br>\n",
    "4) Designing and Experiment <br> \n",
    "5) Analyzing results. \n",
    "\n",
    "***If you would like to know more information about the AB Testing, or the my summary notes of the content, please go to *** \n",
    "[MY MEDIUM BLOG](https://medium.com/@moggirain/a-complete-guide-about-a-b-testing-a1830410a0db)\n",
    "\n",
    "Reference and credits to \n",
    "1. Tammy Rotem: https://www.kaggle.com/tammyrotem/ab-tests-with-python\n",
    "2. Andrew Bauman: https://github.com/baumanab/udacity_ABTesting#summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T22:58:30.296678Z",
     "start_time": "2019-07-13T22:58:30.290213Z"
    }
   },
   "outputs": [],
   "source": [
    "import math as mt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment_Free Trial Screener"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the time of this experiment, Udacity courses currently have two options on the course overview page: \"start free trial\", and \"access course materials\". <br>\n",
    "\n",
    "If the student clicks \"start free trial\", they will be asked to enter their credit card information, and then they will be enrolled in a free trial for the paid version of the course. After 14 days, they will automatically be charged unless they cancel first.\n",
    "\n",
    "If the student clicks \"access course materials\", they will be able to view the videos and take the quizzes for free, but they will not receive coaching support or a verified certificate, and they will not submit their final project for feedback.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To improve the overall student experience and completion rate of Udacity courses through allocating coaches' capacity to support students who are likely to complete the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is A & B ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T19:14:07.224524Z",
     "start_time": "2019-07-09T19:14:07.217965Z"
    }
   },
   "source": [
    "In the experiment, Udacity tested a change where if the student clicked \"start free trial\", they were asked how much time they had available to devote to the course. <br> \n",
    "\n",
    "The difference between experiment and control group will occur after clicking the start free trial. \n",
    "\n",
    "At this point, the student would have the option to continue enrolling in the free trial, or access the course materials for free instead. This screenshot ((https://drive.google.com/file/d/0ByAfiG8HpNUMakVrS0s4cGN2TjQ/view) shows what the experiment looks like.\n",
    "\n",
    "What are A & B versions in this experiment?\n",
    "(https://drive.google.com/file/d/1LUMaZt30y_j3c6OGYMoGf2EDLHdRetoU/view?usp=sharing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hypothesized that free trial screener set clearer expectations for students upfront and thus reduce the number of frustrated students who left the free trial because they didn't have enough time— without significantly reducing the number of students to continue pass the free trial and eventually complete the course. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unit of Diversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ***unit of diversion*** is a cookie, although if the student enrolls in the free trial, they are tracked by user-id from that point forward. \n",
    "\n",
    "The same user-id cannot enroll in the free trial twice. For users that do not enroll, their user-id is not tracked in the experiment, even if they were signed in when they visited the course overview page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"metric\"></a>\n",
    "Here two types of metrics are selected for a successful experiment: Invariate and Evaluation metrics.\n",
    "\n",
    "***Invariate metircs*** are used for sanity checks or A/A experiment before running the experiment, such as checking if the distributions are the same between control and experiment group, to make sure our experiment is not inherently wrong. Invariant metrics usually have a larger unit of diversion, randomly selected, or happens before the experiment starts.  \n",
    "\n",
    "***Evaluation metrics*** are the metrics in which we expect to see a change, and are relevant to the business goals we aim to achieve. For each metric we state a $Dmin$ - which marks the minimum change which is practically significant to the business. For instance, stating that any increase in retention that is under 2%, even if statistically significant, is not practical to the business."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invariant Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Invariate Metrics - Sanity Checks <a class=\"anchor\" id=\"invariate\"></a>\n",
    "\n",
    "| Metric Name  | Metric Formula  | $Dmin$  | Notation |\n",
    "|:-:|:-:|:-:|:-:|\n",
    "| Number of Cookies in Course Overview Page  | # unique daily cookies on page | 3000 cookies  | $C_k$ |\n",
    "| Number of Clicks on Free Trial Button  | # unique daily cookies who clicked  | 240 clicks | $C_l$ |\n",
    "| Free Trial button Click-Through-Probability  | $\\frac{C_l}{C_k}$ | 0.01  | $CTP$ | \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the goal of measurement is how many students will allocate more than 5 hours a week for Udacity courses, which happens before students enrolling in the courses. And thus the clicks and cookies related metircs are for the invariant metircs.User-id, however, will be tracked after enrolling the course,which is not effective. <br>\n",
    "\n",
    "Here, we are concerned about whether students click the \"free trial\" and if students' clicks for the answer to questions about the number of hours they will devote to the course, and thus clicks and cookies are important. Number of cookies is used to tell whether the change is from the questions or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metric "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metrics - Performance Indicators <a class=\"anchor\" id=\"evaluation\"></a>\n",
    "\n",
    "| Metric Name  | Metric Formula  | $Dmin$  | Notation |\n",
    "|:-:|:-:|:-:|:-:|\n",
    "| Gross Conversion   |  $\\frac{enrolled}{C_l}$  | 0.01  | $Conversion_{Gross}$ |\n",
    "| Retention   | $\\frac{paid}{enrolled}$  | 0.01  | $Retention$ |\n",
    "| Net Conversion  |  $\\frac{paid}{C_l}$  | 0.0075 | $Conversion_{Net}$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, CTP won't be a good evaluation metrics, given it can not distinguish the change of free trial between the experiment and control group. <br>\n",
    "\n",
    "Gross Conversion will be a good metric. Gross conversion means the number of enrolled divided by number of clicks. And thus in the experiment group, we hypothesized the number of enrollment will decrease after answering the screener questions, given those who selected <5 hour will not be encouraged to enroll. <br>\n",
    "\n",
    "Retention is number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by number of enrolled students. Udacity could use this metric to check if the the number of paid students are decreasing or not by this test.If the hypothesis is true, the number of students who try free trial reduces without reducing the number of students who are enrolled past 14 days. This means that retention will increase. <br> \n",
    "\n",
    "Net conversion is number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by the number of unique cookies to click the ”Start free trial” button. This metric is also necessary because of the same reason described in Retention. If the hypothesis hold true, the number of students who remain enrolled past 14 days won’t change so much. Therefore, this metric also doesn’t change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating The Baseline Values "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before starting the experiment, we should know how these metrics behave before the change - that is, what are their baseline values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collecting estimators data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"collect\"></a>\n",
    "Udacity offers the following rough estimates for these metrics (presumably collected from aggregates on daily traffic) <br>\n",
    "\n",
    "| Item | Description  | Estimator  |\n",
    "|:-:|:-:|:-:|\n",
    "| Number of cookies | Daily unique cookies to view course overview page  | 40,000  |\n",
    "| Number of clicks | Daily unique cookies to click Free Trial button  | 3,200 |\n",
    "| Number of enrollments | Free Trial enrollments per day  | 660  |\n",
    "| CTP | CTP on Free Trial button  | 0.08  |\n",
    "| Gross Conversion | Probability of enrolling, given a click  | 0.20625  |\n",
    "| Retention | Probability of payment, given enrollment  | 0.53  |\n",
    "| Net Conversion | Probability of payment, given click  | 0.109313 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T22:11:45.513043Z",
     "start_time": "2019-07-13T22:11:45.507014Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store the baseline values into a dictionary\n",
    "baseline = {\"Cookies\":40000,\n",
    "            \"Clicks\":3200,\n",
    "            \"Enrollments\":660,\n",
    "            \"CTP\":0.08,\n",
    "            \"GConversion\":0.20625,\n",
    "            \"Retention\":0.53,\n",
    "            \"NConversion\":0.109313}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-09T22:00:10.104916Z",
     "start_time": "2019-07-09T22:00:10.085208Z"
    }
   },
   "source": [
    "## Estimating Standard Deviation <a class=\"anchor\" id=\"sd\"></a>\n",
    "Once the estimates are collected, we should estimate the standard deviation of a metric. \n",
    "This is computed for ***sample size calculations*** and ***confidence intervals*** for our results. \n",
    "\n",
    "The more variant a metric is, the harder it is to reach a significant result. \n",
    "\n",
    "Assuming a sample size of 5,000 cookies visiting the course overview page per day (as given in project's instructions) - we want to estimate a standard deviation, for the evaluation metrics only. \n",
    "\n",
    "The sample size we are considering should be smaller than the \"population\" we collected and small enough to have two groups with that size. Given the sample size of 5000 pageviews for each metric, we will rescale the baseline values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T22:11:45.612684Z",
     "start_time": "2019-07-13T22:11:45.599765Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cookies': 5000,\n",
       " 'Clicks': 400.0,\n",
       " 'Enrollments': 82.5,\n",
       " 'CTP': 0.08,\n",
       " 'GConversion': 0.20625,\n",
       " 'Retention': 0.53,\n",
       " 'NConversion': 0.109313}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rescale the counts estimates when sample = 5000\n",
    "prop = 5000 / 40000\n",
    "baseline['Cookies'] = 5000\n",
    "baseline['Clicks'] = baseline['Clicks'] * prop\n",
    "baseline['Enrollments'] = baseline['Enrollments'] * prop\n",
    "baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Standard Devisation <a class=\"anchor\" id=\"estimate\"></a>\n",
    "\n",
    "In order to estimate variance analytically, we can assume metrics which are probabilities ($\\hat{p}$) are binomially distributed, so we can use this formula for the standard deviation: <br>\n",
    "<center><font size=\"4\">$SD=\\sqrt{\\frac{\\hat{p}*(1-\\hat{p})}{n}}$</font></center><br>\n",
    "This assumption is only valid when the **unit of diversion** of the experiment is equal to the **unit of analysis** (the denominator of the metric formula). In the cases when this is not valid, the actual variance might be different and it is recommended to estimate it empirically.\n",
    "\n",
    "For each metric, we need to plug two variables into the formula: <br>\n",
    "$\\hat{p}$ - baseline probability of the event to occur <br>\n",
    "$ n $ - sample size <br>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T22:11:45.782016Z",
     "start_time": "2019-07-13T22:11:45.778204Z"
    }
   },
   "outputs": [],
   "source": [
    "def standard_d (p, n, round_d = 4):\n",
    "    return round(np.sqrt(p * (1 - p)/n),round_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gross Conversion \n",
    "\n",
    "The baseline probability for Gross Conversion can be calculated by the number of users to enroll in a free trial divided by the number of cookies clicking the free trial. In other words, the probability of enrollment given a click. \n",
    "\n",
    "In this case, the unit of diversion (Cookies), that is the element by which we differentiate samples and assign them to control and experiment groups, is equall to the unit of analysis (cookies who click), that is the denominator of the formula to calculate Gross Conversion (GC). When this is the case, this analytic estimate of variance is sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T22:11:45.848676Z",
     "start_time": "2019-07-13T22:11:45.842050Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0202"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and compute the Stansard Deviation(sd) rounded to 4 decimal digits.\n",
    "GC={}\n",
    "GC[\"d_min\"]=0.01\n",
    "GC[\"p\"]=baseline[\"GConversion\"]\n",
    "GC[\"n\"]=baseline[\"Clicks\"]\n",
    "GC[\"sd\"] = standard_d(GC[\"p\"], GC[\"n\"], round_d = 4)\n",
    "GC[\"sd\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retention\n",
    "\n",
    "The baseline probability for retention is the number of paying users (enrolled after 14 free days) divided by the number of total enrolled users. \n",
    "In other words, the probability of payment, given enrollment. The sample size is the number of enrolled users. \n",
    "In this case, unit of diversion is not equal to unit of analysis (users who enrolled) so an analytical estimation is not enough - if we had the data for these estimates, we would want to estimate this variance empirically as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T22:11:45.906829Z",
     "start_time": "2019-07-13T22:11:45.899777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0549"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rt={}\n",
    "Rt[\"d_min\"]=0.01\n",
    "Rt[\"p\"]=baseline[\"Retention\"]\n",
    "Rt[\"n\"]=baseline[\"Enrollments\"]\n",
    "Rt[\"sd\"]=standard_d(Rt[\"p\"], Rt[\"n\"], round_d = 4)\n",
    "Rt[\"sd\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Conversion \n",
    "\n",
    "The baseline probability for the net conversion is the number of paying users divided by the number of cookies that clicked the free trial button. In other words, the probability of payment, given a click. The sample size is the number of cookies that clicked. In this case, the unit of analysis and diversion are equal so we expect a good enough estimation analytically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T22:11:45.975055Z",
     "start_time": "2019-07-13T22:11:45.968435Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0156"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NC={}\n",
    "NC[\"d_min\"]=0.0075\n",
    "NC[\"p\"]=baseline[\"NConversion\"]\n",
    "NC[\"n\"]=baseline[\"Clicks\"]\n",
    "NC[\"sd\"]=standard_d(NC[\"p\"], NC[\"n\"], round_d = 4)\n",
    "NC[\"sd\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Analytical Estimate of Standard Deviation of Evaluation Metrics***\n",
    "\n",
    "| Evaluation Metric | Standard Deviation |\n",
    "|:-:|:-:|\n",
    "|Gross Conversion|.0202 |\n",
    "|Retention|\t.0549 |\n",
    "|Net Conversion\t|.0156 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment Sizing <a class=\"anchor\" id=\"sizing\"></a>\n",
    "Once we have estimated our metrics in the baseline (most importantly, their estimated variance) we can calculate the minimal number of samples we need so that our experiment will have enough statistical power, as well as siginificance.\n",
    "\n",
    "Given $\\alpha=0.05$ (significance level ) and $\\beta=0.2$ (power), we want to estimate how many total pageviews (cookies who viewed the course overview page) we need in the experiment. This amount will be divided into tthe two groups: control and experiment. This calculation can be done using an [online calculator](http://www.evanmiller.org/ab-testing/sample-size.html) or by calculating directly using the required formula.\n",
    "\n",
    "The minimum sample size for control and experiment groups, which provides probability of Type I Error $\\alpha$, Power $1-\\beta$, detectable effect $d$ and baseline conversion rate $p$ (simple hypothesis $H_0 : P_{cont} - P_{exp} = 0$ against simple alternative $H_A : P_{cont} - P_{exp} = d$  is:\n",
    "\n",
    "<center> <font size=\"5\"> $n = \\frac{(Z_{1-\\frac{\\alpha}{2}}sd_1 + Z_{1-\\beta}sd_2)^2}{d^2}$</font>, with: <br><br>\n",
    "$sd_1 = \\sqrt{p(1-p)+p(1-p)}$<br><br>\n",
    "$sd_2 = \\sqrt{p(1-p)+(p+d)(1-(p+d))}$ </center><br>\n",
    "\n",
    "Now, let's break down what inputs we need and which calculations still need to be made. Regarding inputs, we have all the data we need:\n",
    "Type 1 error ($\\alpha$), power ($1-\\beta$), detectable change ($d = D_{min}$) and baseline conversion rate (our $\\hat{p}$ ).\n",
    "What we need to calculate: \n",
    "* Get Z score for $1-\\frac{\\alpha}{2}$ and for $1-\\beta$\n",
    "* Get standard deviations 1 & 2, that is for both the baseline and for expected changed rate\n",
    "All these components will finally yield the number we need."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get z-score critical value and standard deviations \n",
    "We are used to looking up this value in a table, but gladly we can use python's scipy.stats.norm package to get all the required methods for normal distribution. The ppf method gives us access to the Percent Point Function (ppf) or Quantile Function, and besides it being the inverse of the Cummulative Distribution Function (cdf), this is the functions that will give back our required critical z-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T22:11:46.171418Z",
     "start_time": "2019-07-13T22:11:46.165862Z"
    }
   },
   "outputs": [],
   "source": [
    "#Inputs: required alpha value (alpha should already fit the required test)\n",
    "#Returns: z-score for given alpha\n",
    "def get_z_score(alpha):\n",
    "    return norm.ppf(alpha)\n",
    "\n",
    "# Inputs p-baseline conversion rate which is our estimated p and d-minimum detectable change\n",
    "# Returns\n",
    "def get_sds(p,d):\n",
    "    sd1 = np.sqrt(p * (1-p) + p * (1-p))\n",
    "    sd2 = np.sqrt(p *(1-p) + (p + d)* (1-(p+d)))\n",
    "    sds = [sd1, sd2]\n",
    "    return sds\n",
    "\n",
    "# Inputs:sd1-sd for the baseline,sd2-sd for the expected change,alpha,beta,d-d_min,p-baseline estimate p\n",
    "# Returns: the minimum sample size required per group according to metric denominator\n",
    "def get_sampSize(sds,alpha,beta,d):\n",
    "    n = pow ((get_z_score(1 - alpha / 2) * sds[0] + get_z_score (1 - beta) * sds[1]),2) / pow(d,2)\n",
    "    return n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Sample Size per Metric <a class=\"anchor\" id=\"calc\"></a>\n",
    "We are now going to calculate the number of samples required for the experiment per metric. This size should be considered in terms of efficacy of duration and exposure: how long will it take to get this many samples for the experiment.\n",
    "\n",
    "***Pageviews for Each Evaluation Metric to Achieve Target Statistical Power***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gross Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T22:11:46.284645Z",
     "start_time": "2019-07-13T22:11:46.277233Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "645875.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GC[\"SampSize\"]=round(get_sampSize(get_sds(GC[\"p\"],GC[\"d_min\"]),0.05,0.2,GC[\"d_min\"]))\n",
    "# pageview for two groups\n",
    "GC[\"SampSize_total\"]=round(GC[\"SampSize\"]/ 0.08 *2)\n",
    "GC[\"SampSize_total\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Conversion: 20.625% <Br>\n",
    "Minimum Detectable Effect: 1%\n",
    "Alpha: 5% <br>\n",
    "Beta: 20% <br>\n",
    "Sensitivity (1 - Beta): 80% <br>\n",
    "Sample Size = 25,835 clicks/group <br>\n",
    "Number of groups = 2 (experiment and control)<br>\n",
    "Total sample size = 51,670 clicks <br>\n",
    "Clicks/Pageview: 3200/40000 = 0.08 <br>\n",
    "Pageviews Required = 51,670 / 0.08 = 6,45,875"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T22:11:46.446003Z",
     "start_time": "2019-07-13T22:11:46.436637Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4737818.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting an integer value \n",
    "Rt[\"SampSize\"]=round(get_sampSize(get_sds(Rt[\"p\"],Rt[\"d_min\"]),0.05,0.2,Rt[\"d_min\"]))\n",
    "Rt[\"SampSize\"]\n",
    "# convert enrollment per group to the total number of clicks and to page views\n",
    "Rt[\"SampSize_total\"] = round(Rt[\"SampSize\"] / 0.20625 / 0.08 * 2)\n",
    "Rt[\"SampSize_total\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This number is slightly different than what we calculate through the online calculator. \n",
    "Here is another version of answer. \n",
    "\n",
    "Baseline Conversion: 53% <br>\n",
    "Minimum Detectable Effect: 1% <br>\n",
    "Alpha: 5% <br>\n",
    "Beta: 20% <br>\n",
    "Sensitivity (1 - Beta): 80% <br>\n",
    "Sample size = 39,155 enrollments/group <br>\n",
    "Number of groups = 2 (experiment and control) <br>\n",
    "Total sample size = 78,230 enrollments <br>\n",
    "Enrollments/pageview: 660/40000 = 0.0165  <br>\n",
    "Pageviews = 78,230/0.0165 = 47,41,212"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-13T22:11:46.558164Z",
     "start_time": "2019-07-13T22:11:46.551123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685325.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NC[\"SampSize\"]=round(get_sampSize(get_sds(NC[\"p\"],NC[\"d_min\"]),0.05,0.2,NC[\"d_min\"]))\n",
    "NC[\"SampSize_total\"] = NC[\"SampSize\"] * 2 / (3200/40000)\n",
    "NC[\"SampSize_total\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline Conversion: 10.9313% <br>\n",
    "Minimum Detectable Effect: 1% <br>\n",
    "Alpha: 5% <br>\n",
    "Beta: 20% <br>\n",
    "Sensitivity (1 - Beta): 80% <br>\n",
    "Sample size = 27,413 clicks/group <br>\n",
    "Number of groups = 2 (experiment and control) <br>\n",
    "Total sample size = 54,826 clicks <br>\n",
    "Clicks/pageview: 3200/40000 = 0.08  <br>\n",
    "Pageviews = 54,826/0.08 = 6,85,325"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pageviews required is maximum of pageviews required for Gross Conversion, Retention, Net Conversion. Therefore, the required pageviews is 47,41,212."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duration and Exposure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we divert 100% of traffic, given 40,000 page views per day, the experiment would take about 119 days.\n",
    "\n",
    "This duration with full diversion is too time consuming for running an experiment and presents some potential risks for business, such as frustrated students, lower conversion and retention, and inefficient use of coaching resources, and the opportunity riks of performing other experiments. \n",
    "\n",
    "Therefore, if we eliminate retention, we are left with Gross Conversion and Net Conversion, and the pageview requirement will be reduced to  to 685,325, and an about 18 day experiment with 100% diversion and or 35 days given 50% diversion.In terms of timing, an 18 day experiment is more reasonable, but % diversion may be scaled down depending on other experiments of interest to be performed concurrently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Analysis\n",
    "\n",
    "The last step is to prove the experiment using the actual data. Three parts are included in this section: \n",
    "\n",
    "1) Sanity Checks <br>\n",
    "2) Examining effect size <br>\n",
    "3) Sign Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T13:32:12.142993Z",
     "start_time": "2019-07-14T13:32:12.070385Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37 entries, 0 to 36\n",
      "Data columns (total 5 columns):\n",
      "Date           37 non-null object\n",
      "Pageviews      37 non-null int64\n",
      "Clicks         37 non-null int64\n",
      "Enrollments    23 non-null float64\n",
      "Payments       23 non-null float64\n",
      "dtypes: float64(2), int64(2), object(1)\n",
      "memory usage: 1.5+ KB\n"
     ]
    }
   ],
   "source": [
    "experiment = pd.read_csv(\"./experiment_data_20190713.csv\", sep=',', encoding='ISO-8859-1')\n",
    "control = pd.read_csv(\"./control_data_20190713.csv\", sep=',', encoding='ISO-8859-1')\n",
    "experiment.head()\n",
    "control.head()\n",
    "experiment.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T13:33:59.542236Z",
     "start_time": "2019-07-14T13:33:59.364971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x = experiment.Pageviews,\n",
    "        bins = 15,\n",
    "        density = 1,\n",
    "        facecolor = 'blue',\n",
    "        alpha = 0.5)\n",
    "plt.hist(x = control.Pageviews,\n",
    "        bins = 15,\n",
    "        density = 1,\n",
    "        facecolor = 'red',\n",
    "        alpha = 0.5)\n",
    "# alpha is to set the transparent level \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick check of the pageviews distribution of the control and experiment group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"sanity\"></a>\n",
    "Sanity checks is to help verify that the experiment was conducted as expected and that other factors did not influence the data which we collected. This also makes sure that data collection was correct.\n",
    "\n",
    "We have 3 Invariant metrics:: \n",
    "* Number of Cookies in Course Overview Page\n",
    "* Number of Clicks on Free Trial Button\n",
    "* Free Trial button Click-Through-Probability\n",
    "\n",
    "Two of these metrics are simple counts: the number of cookies or number of clicks and the third is a probability (CTP). We will use two different ways of checking whether these obsereved values are like we expect. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Checks for differences between counts <a class=\"anchor\" id=\"check_counts\"></a>\n",
    "**Number of cookies who viewed the course overview page** \n",
    "- Starting from this simpel invariant metric, we want to count the total amount of cookie pageviews we diverted to each group and see if there is a significant difference in the amount of cookies. A significant difference will imply a biased experiment that we should not rely on it's results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of pageviews in the two groups are close. The next step is to ensure such difference in amount is not significant and random. Given we are expecting two groups are distributed with half and half amount, so we define a binominal random variable for a single experiment. We expect the probabily of 0.5 out of N experiments. \n",
    "\n",
    "We approaximate the binominal distribution to a normal distribution when n is large enough with a mean of p and $ SD$  = $\\sqrt{\\frac{p(1-p)}{N}}$\n",
    "<center> <font size=\"4\"> $ X$~$N( p,\\sqrt{\\frac{p(1-p)}{N}})$ </font></center> \n",
    "\n",
    "Our test goal: whether our observed $\\hat{p}$ (number of samples in control divided by total number of damples in both groups) is not significantly different than $p=0.5$. In order to do that we can calculate the margin of error acceptable at a 95% confidence level:\n",
    "<center> <font size=\"4\"> $ ME=Z_{1-\\frac{\\alpha}{2}}SD$ </font></center>\n",
    "Finally, a [confidence interval](https://en.wikipedia.org/wiki/Confidence_interval) can be derived to tell us in which range an observed $p$ can exist and be acceptable as \"the same\" as the expected value.\n",
    "<center> <font size=\"4\"> $ CI=[\\hat{p}-ME,\\hat{p}+ME]$ </font></center>\n",
    "When our obsereved $\\hat{p}$ is within this range, all is well and the test was passed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T00:53:43.070371Z",
     "start_time": "2019-07-14T00:53:43.060542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of pageviews in the control group : 345543.0\n",
      "number of Pageviews in the experiment group : 344660\n",
      "number of pageviews in total : 690203.0\n",
      "The confidence interval is between 0.4988 and 0.5012 p_hat is  0.5006\n"
     ]
    }
   ],
   "source": [
    "# The toal number of pageviews in control and experiment groups\n",
    "control_total_page = control.Pageviews.sum()\n",
    "experiment_total_page = experiment.Pageviews.sum()\n",
    "page_total = control_total_page + experiment_total_page\n",
    "print(\"number of pageviews in the control group :\", control_total_page)\n",
    "print(\"number of Pageviews in the experiment group :\" , experiment_total_page )\n",
    "print(\"number of pageviews in total :\", total)\n",
    "# calculate the confidence interval \n",
    "p=0.5\n",
    "alpha=0.05\n",
    "p_hat=round(control_total_page/(page_total),4)\n",
    "sd = np.sqrt(p * (1-p)/ (page_total))\n",
    "ME=round(get_z_score(1-(alpha/2))*sd,4)\n",
    "print (\"The confidence interval is between\",p-ME,\"and\",p+ME,\"p_hat is \",p_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T00:43:05.404301Z",
     "start_time": "2019-07-14T00:43:05.399489Z"
    }
   },
   "source": [
    "**Number of cookies who clicked the Free Trial Button**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T01:01:10.974322Z",
     "start_time": "2019-07-14T01:01:10.967966Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confidence interval is between 0.4959 and 0.5041 and p_hat is 0.5005\n"
     ]
    }
   ],
   "source": [
    "control_total_clicks = control.Clicks.sum()\n",
    "experiment_total_clicks = experiment.Clicks.sum()\n",
    "clicks_total = control_total_clicks + experiment_total_clicks\n",
    "\n",
    "p_hat=round(control_total_clicks / clicks_total,4)\n",
    "sd= np.sqrt(p*(1-p)/clicks_total)\n",
    "ME=round(get_z_score(1-(alpha/2))*sd,4)\n",
    "print (\"The confidence interval is between\",p-ME,\"and\",p+ME,\"and p_hat is\",p_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity Checks for differences between probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"check_prob\"></a>\n",
    "** Click-through-probability of the Free Trial Button**\n",
    "\n",
    "For the probabilities, we intend to test the proportion of clicks given a pageview (CTP) is about the same in both groups, meaning ($CTP_{exp}-CTP_{cont}=0$), with an acceptable margin of error, dictated by our calculated confidence interval. The calculation of the standard error is through the pooled standard error between experiment and control group. \n",
    "\n",
    "<center><font size=\"4\">$SD_{pool}=\\sqrt{\\hat{p_{pool}}(1-\\hat{p_{pool}}(\\frac{1}{N_{cont}}+\\frac{1}{N_{exp}})}$</font></center>\n",
    "with <br> <center><font size=\"5\"> $\\hat{p_{pool}}=\\frac{x_{cont}+x_{exp}}{N_{cont}+N_{exp}}$ </font></center>\n",
    "\n",
    "CTP is a proportion in a population (amount of events x in a population n) like the amount of clicks out of the amount of pageviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T01:20:09.224438Z",
     "start_time": "2019-07-14T01:20:09.215585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confidence interval is between -0.5618 and 0.5618 and d_hat is 0.0001\n"
     ]
    }
   ],
   "source": [
    "control_ctp = control_total_clicks / control_total_page\n",
    "experiment_ctp = experiment_total_clicks / experiment_total_page\n",
    "d_hat = round(experiment_ctp - control_ctp,4)\n",
    "p_pooled = clicks_total / page_total\n",
    "sd_pooled = np.sqrt(p_pooled * (1 - p_pooled * (1 / control_total_page + 1 / experiment_total_page)))\n",
    "ME=round(get_z_score(1-(alpha/2))*sd_pooled,4)\n",
    "print (\"The confidence interval is between\",0-ME,\"and\",0+ME,\"and d_hat is\",d_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, the sanity check result for the three invariant metrics are listed below: \n",
    "\n",
    "| Invariant Metric | Upper Bound | Lower Bound | Observed | \n",
    "|:-:|:-:|:-:|:-:|\n",
    "| Number of Cookies in Course Overview Page | 0.4988  | 0.5012 | 0.5006 | \n",
    "| Number of Clicks on Free Trial Button | 0.4959 |  0.5041 | 0.5005 |\n",
    "| Free Trial button CTP  |-0.5618 | 0.5618 | 0.0001 | \n",
    "\n",
    "Three observed values are within the confidence interval and thus three experiment result has passed the sanity check. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examing Effect Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"effect\"></a>\n",
    "The next step is looking at the changes between the control and experiment groups with regard to our evaluation metrics to ensure the statistically significant difference and most importantly practically significant (the difference is \"big\" enough to make the experimented change beneficial to the company).\n",
    "\n",
    "**Procedure**: \n",
    "1. Calculate pooled probability:\n",
    "<center><font size=\"4\">$\\hat{p_{pool}}=\\frac{x_{cont}+x_{exp}}{N_{cont}+N_{exp}}$ </font></center>\n",
    "2. Calculate pooled standard devisation:\n",
    "<center><font size=\"4\">$SD_{pool}=\\sqrt{\\hat{p_{pool}}(1-\\hat{p_{pool}}(\\frac{1}{N_{cont}}+\\frac{1}{N_{exp}})}$</font></center>\n",
    "<br>\n",
    "    \n",
    "3. Calculate the practical significance difference \n",
    "<center><font size=\"4\"> $\\hat{d}=\\frac{x_{exp}}{N_{exp}}-\\frac{x_{cont}}{N_{cont}}$</font></center><br>\n",
    "\n",
    "4. Calculate margin of errors:\n",
    "<center> <font size=\"4\"> $ ME=Z_{1-\\frac{\\alpha}{2}}SD$ </font></center>\n",
    "\n",
    "5. Calculate Confidence Interval \n",
    "<center> <font size=\"4\"> $ CI=[\\hat{d}-ME,\\hat{d}+ME]$ </font></center>\n",
    "\n",
    "A metric is statistically significant if the confidence interval does not include 0 (that is, you can be confident there was a change), and it is practically significant if the confidence interval does not include the practical significance boundary or |d_hat| > dmin (that is, you can be confident there is a change that matters to the business.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gross Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Gross Conversion**\n",
    "\n",
    "> **Important:** The given spreadsheet lists pageviews and clicks for 39 days, while it only lists enrollments and payments for 23 days. So, when working with enrollments and payments we should notice using only the corresponding pageviews and clicks, and not all of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T14:44:54.250477Z",
     "start_time": "2019-07-14T14:44:54.240015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The change due to the experiment is -0.0206\n",
      "Confidence Interval: [ -0.0292 , -0.012 ]\n",
      "The change is statistically significant if the CI doesn't include 0. In that case, it is practically significant if -0.01 is not in the CI as well.\n"
     ]
    }
   ],
   "source": [
    "# Count the total clicks from complete records only \n",
    "clicks_cont=control[\"Clicks\"].loc[control[\"Enrollments\"].notnull()].sum()\n",
    "clicks_exp=experiment[\"Clicks\"].loc[experiment[\"Enrollments\"].notnull()].sum()\n",
    "\n",
    "#Gross Conversion - number of enrollments divided by number of clicks\n",
    "enrollments_cont=control[\"Enrollments\"].sum()\n",
    "enrollments_exp=experiment[\"Enrollments\"].sum()\n",
    "\n",
    "# Check difference between GC_cont and GC_exp groups\n",
    "GC_cont=enrollments_cont/clicks_cont\n",
    "GC_exp=enrollments_exp/clicks_exp\n",
    "GC_pooled=(enrollments_cont + enrollments_exp)/(clicks_cont + clicks_exp)\n",
    "GC_sd_pooled= np.sqrt(GC_pooled*(1-GC_pooled)*(1/clicks_cont+1/clicks_exp))\n",
    "GC_ME=round(get_z_score(1-alpha/2)*GC_sd_pooled,4)\n",
    "GC_diff=round(GC_exp - GC_cont, 4)\n",
    "print(\"The change due to the experiment is\",GC_diff)\n",
    "print(\"Confidence Interval: [\",GC_diff-GC_ME,\",\",GC_diff+GC_ME,\"]\")\n",
    "print (\"The change is statistically significant if the CI doesn't include 0. In that case, it is practically significant if\",-GC[\"d_min\"],\"is not in the CI as well.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this result there was a change due to the experiment, that change was both statistically and practically significant. \n",
    "We have a negative change of 2.06%, when we were willing to accept any change greater than 1%. This means the Gross Conversion rate of the experiment group (the one exposed to the change, i.e. asked how many hours they can devote to studying) has decreased as expected by 2% and this change was significant. This means  less people enrolled in the Free Trial after due to the pop-up. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Net Conversion \n",
    "We hypothesized the fraction of paid learners (out of the clicks)decrease in the experiment group. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T14:53:41.061622Z",
     "start_time": "2019-07-14T14:53:41.054430Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The change due to the experiment is -0.0049\n",
      "Confidence Interval: [ -0.0116 , 0.0018000000000000004 ]\n",
      "The change is statistically significant if the CI doesn't include 0. In that case, it is practically significant if 0.0075 is not in the CI as well.\n"
     ]
    }
   ],
   "source": [
    "#Net Conversion - number of payments divided by number of clicks\n",
    "payments_cont=control[\"Payments\"].sum()\n",
    "payments_exp=experiment[\"Payments\"].sum()\n",
    "\n",
    "NC_cont=payments_cont/clicks_cont\n",
    "NC_exp=payments_exp/clicks_exp\n",
    "NC_pooled=(payments_cont+payments_exp)/(clicks_cont+clicks_exp)\n",
    "NC_sd_pooled=mt.sqrt(NC_pooled*(1-NC_pooled)*(1/clicks_cont+1/clicks_exp))\n",
    "NC_ME=round(get_z_score(1-alpha/2)*NC_sd_pooled,4)\n",
    "NC_diff=round(NC_exp-NC_cont,4)\n",
    "print(\"The change due to the experiment is\",NC_diff)\n",
    "print(\"Confidence Interval: [\",NC_diff-NC_ME,\",\",NC_diff+NC_ME,\"]\")\n",
    "print (\"The change is statistically significant if the CI doesn't include 0. In that case, it is practically significant if\",NC[\"d_min\"],\"is not in the CI as well.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we got a change size of less than a 0.5%, a very small decrease which is not statistically significant, and as such not practically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, the effect size for the two evaluation metrics are listed below: \n",
    "\n",
    "| Evaluation Metric | Lower Bound | Upper Bound | Observed | dmin | Result|\n",
    "|:-:|:-:|:-:|:-:|:-:|:-:|\n",
    "| Gross Conversion | -0.0292  | -0.012 | -0.0206 | -0.01 | statistically significant & practically significant|\n",
    "| Net Conversion | -0.0116 |  0.0018 | 0.0075 | -0.0049| Neither statistically significany or practically significant|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double Check with Sign Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a class=\"anchor\" id=\"sign_tests\"></a>\n",
    "A sign test is another method to validate the result obtained above. \n",
    "We check if the trend of change we observed (increase or decrease) was evident in the daily data. We are going to compute the metric's value per day and then count on how many days the metric was lower in the experiment group and this will be the number of success for the binomial variable. We then check the proportion of days of success out of all the available days."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T15:23:08.059816Z",
     "start_time": "2019-07-14T15:23:07.994513Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of cases for GC: 4 \n",
      " No. of cases for NC: 10 \n",
      " No. of total cases 23\n"
     ]
    }
   ],
   "source": [
    "# Prepare the dataset \n",
    "full = control.join(other=experiment, how = \"inner\", lsuffix= \"_cont\", rsuffix=\"_exp\")\n",
    "# full.head()\n",
    "# filter the complete data records\n",
    "full = full.loc[full[\"Enrollments_cont\"].notnull()]\n",
    "# full.count()\n",
    "# assign the label=1 if experiment value is greater than the control vale \n",
    "cont_x = full[\"Enrollments_cont\"] / full[\"Clicks_cont\"]\n",
    "cont_y = full[\"Enrollments_exp\"] / full[\"Clicks_exp\"]\n",
    "full[\"GC\"] = np.where(cont_x < cont_y, 1, 0)\n",
    "# full.GC\n",
    "# build a column for netconversion \n",
    "cont_a = full[\"Payments_cont\"] / full[\"Clicks_cont\"]\n",
    "cont_b = full[\"Payments_exp\"] / full[\"Clicks_exp\"]\n",
    "full[\"NC\"] = np.where(cont_a < cont_b, 1, 0)\n",
    "# calculate the count \n",
    "GC_1 = full.GC[full[\"GC\"] == 1].count()\n",
    "NC_1 = full.NC[full[\"NC\"] == 1].count()\n",
    "n = full.GC.count()\n",
    "print(\"No. of cases for GC:\",GC_1,'\\n',\n",
    "      \"No. of cases for NC:\",NC_1,'\\n',\n",
    "      \"No. of total cases\",n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T15:19:26.968743Z",
     "start_time": "2019-07-14T15:19:26.950924Z"
    }
   },
   "source": [
    "### Sign Test without the Online Calculator "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part can be done using[online sign test calculator](https://www.graphpad.com/quickcalcs/binomial2/). We will implement it with the statistical procedure <br>\n",
    "\n",
    "After counting the number of days where experiment group had a higher metric value than that of the control group, we intend to test the significance of the such result for a new experiment.\n",
    "Our assumption is the such distribution follows a random binomimal distribution with $p=0.5$ and $n=$total number of days. We continue to perform a two-tailed test to check for random variable x if the $p-value$ is greater than the critical value $\\alpha$ <br>\n",
    "Here is the mathmatical formula:\n",
    "\n",
    "<center><font size=\"4\"> $p(successes )=\\frac{n!}{x!(n-x)!}p^x(1-p)^{n-x}$ </font></center>\n",
    "\n",
    "Recall that a $p-value$ is the probability of observing a test statistic as or more extreme than that observed. If we observed 2 days like that, the $p-value$ for the test is: $p-value = P(x <= 2)$. We only need to remember the following:<br>\n",
    "<center>$P(x<=2)=P(0)+P(1)+P(2)$.</center><br>For more detailed information, visit [webpage](http://sphweb.bumc.bu.edu/otlt/mph-modules/bs/bs704_nonparametric/BS704_Nonparametric5.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T15:47:22.984930Z",
     "start_time": "2019-07-14T15:47:22.980335Z"
    }
   },
   "outputs": [],
   "source": [
    "# build a funciton for binominal probability \n",
    "def get_prob(x,n):\n",
    "    p= round(mt.factorial(n)/(mt.factorial(x)* mt.factorial(n-x))*0.5**x*0.5**(n-x),4)\n",
    "    return p\n",
    "#next a function to compute the pvalue from probabilities of maximum x\n",
    "def get_2tail_pvalue(x,n):\n",
    "    p = 0\n",
    "    for i in range(0, x+1):\n",
    "        p = p + get_prob (i, n)\n",
    "    return 2 * p\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sign Test Result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-14T15:47:24.060807Z",
     "start_time": "2019-07-14T15:47:24.053176Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GC Change : 0.0026000000000000003\n",
      "NC Change : 0.6774\n"
     ]
    }
   ],
   "source": [
    "GC_change = get_2tail_pvalue(GC_1, n)\n",
    "print(\"GC Change :\", GC_change)\n",
    "NC_change = get_2tail_pvalue(NC_1, n)\n",
    "print(\"NC Change :\", NC_change)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In summary, the sign test result is listed below:\n",
    "\n",
    "| Evaluation Metric | p-value for sign test| statistically sig @ alpha = 0.5?|\n",
    "|:-:|:-:|:-:|\n",
    "| Gross Conversion | 0.0026  | Yes | \n",
    "| Net Conversion | 0.6774 |  No|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of conducting this experiment was to test if the free trial screener could improve learning experience and completion rates. Udacity students were diverted by cookies into experiment and control group. The students in the experiment group will be directed to ask their devoted time to the course after clicking a \"start free trial button\", and suggested to enroll or use the free course materials while the control group will see the regular enrollment button or use the free material in the homepage. \n",
    "\n",
    "We selected three invariant metrics (Number of Cookies, Number of clicks on \"start free trial\", and Click-Through-Probability)as our metrics for validation and sanity check. The evaluation metrics we selected are Gross Conversion (enrollment/cookies) and Net Conversion (payments/cookies). There are two requirements to performence. The requirement run the experiment are: \n",
    "\n",
    "1) The null hypothesis is rejected for both evaluation metircs, meaning there is no difference in the evaluation metrics between the groups.\n",
    "2) A practical signifcance threshold was set for each metric should be met, meaning the minimun difference should exceed the practical signficance threshold. \n",
    "\n",
    "We decided not to use the Bonferonni correction, given our acceptance criteria requires statiscally signifcant differences for ALL evaluation metrics, and so the use of the Bonferonni correction is not appropriate. The Bonferonni correction is a method for controlling for type I errors (false positives) when using multiple metrics in which relevance of ANY of the metrics matches the hypothesis. In this case the risk of type I errors increases as the number of metrics increases (signifcance by random chance). In our case in which ALL metrics must be relevant to launch, the risk of type II errors (false negatives) increases as the number of metrics increases, so it stands to reason that controlling for false positives is not consistent with our acceptance criteria.\n",
    "\n",
    "The results revealed the equal distribution of cookies into the control and experimental groups for the invariant metrics, at the 95% CI. A difference in gross conversion was found to be statistically signficant at the 95% CI and was practically significant, and thus the null hypothesis was rejected. However, the Net Conversion was found to be neither statistically nor practically signficant at the 95% CI. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect filtering students as a function of study time commitment would improve the overall student experience and the coaches' capacity to support students who are likely to complete the course, without significantly reducing the number of students who continue past the free trial. \n",
    "\n",
    "A statistically and practically signficant decrease in Gross Conversion was observed but with no significant differences in Net Conversion. This translates to a decrease in enrollment not coupled to an increase in students staying for the requisite 14 days to trigger payment. \n",
    "\n",
    "Given these two reason, I suggest not launching the experiment but to pursue other experiments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Follow-up Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the goal of improve learner experience and increase the completion and retention rate, there are a variety of strategies, such as using the badge system to motivate students sustain longer, using the return-fee-along-with-the-time-to-stay-in-the-class. For example, students are prepaid the course fee for certain time, and if they sustain longer, the system will return or deduct the fee as the reward for retention. \n",
    "\n",
    "I suggest to design an experiment that provides the over-course submission option for students that minimize the time cost for some students. Students who choose to go for enrollment has the chance to submit the course assignments and tasks within the whole course period, even if they have late submission. For those students who do not have the average time of 5h a week but may have a packed time to complete the course, such as the weekend, will be a better choice. This gives those students, especially the working professionals a chance to complete the course. \n",
    "\n",
    "The experiment would function in the following manner.\n",
    "\n",
    "Setup: Upon enrollment students will either be randomly assigned to a control group in which they will be given the chance to submit the homework at a rigid deadline, or an experiment group in which they are notified as long as they submit the assignments within the course period, they will receive the completion certificate.\n",
    "\n",
    "Null Hypothesis: Allowing the cross-course submission will not increase the number of students enrolled beyond the 14 day free trial period by a significant amount.\n",
    "\n",
    "Unit of Diversion: The unit of diversion will be user-id as the change takes place after a student creates an account and enrolls in a course.\n",
    "\n",
    "Invariant Metrics: The invariant metric will be user-id, since an equal distribution between experiment and control would be expected as a property of the setup.\n",
    "\n",
    "Evaluation Metrics: The evaluation metric willl be Retention. A statistically and practically significant increase in Retention would indicate that the change is succesful.\n",
    "\n",
    "If a statistically and practically signifcant positive change in Retention is observed, assuming an acceptable impact on overall Udacity resources (setting up and maintaining teams will require resource use), the experiment will be launched.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "174px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
